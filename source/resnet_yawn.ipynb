{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"name":"resnet_yawn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"AmlSpqYyu8ze"},"source":["\n","\n","# Drowsiness Detection ResNet\n","\n","a convolutional neural network with a ResNet architecture [(He et al, 2016)](https://arxiv.org/abs/1512.03385)."]},{"cell_type":"code","metadata":{"id":"lO4g0RQOu8zt"},"source":["skip_training = False  # Set this flag to True before validation and submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ut38RaKMD0Ee","executionInfo":{"status":"ok","timestamp":1635670791335,"user_tz":-60,"elapsed":30463,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"d88b6c09-f3e0-4572-9ff9-29543031a6b1"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/DrowsinessDetection/source')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"xd2TjIFKu8zy"},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import tools\n","import tests"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEIaHJd6u8zz","executionInfo":{"status":"ok","timestamp":1635672206848,"user_tz":-60,"elapsed":241,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"1bf09bbf-8027-428f-9c44-6091741abb81"},"source":["# When running on your own computer, you can specify the data directory by:\n","data_dir = tools.select_data_dir('/content/drive/MyDrive/DrowsinessDetection')\n","source_dir = '/content/drive/MyDrive/DrowsinessDetection/source'\n","print(data_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The data directory is /content/drive/MyDrive/DrowsinessDetection\n","/content/drive/MyDrive/DrowsinessDetection\n"]}]},{"cell_type":"code","metadata":{"id":"vP7v4dg1u8z3"},"source":["# Select the device for training (use GPU if you have one)\n","device = torch.device('cuda:0')\n","#device = torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzTRfcyp3b8_","executionInfo":{"status":"ok","timestamp":1635670817413,"user_tz":-60,"elapsed":75,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"13480319-5e58-492f-b452-e45867ec802e"},"source":["print(data_dir)\n","data_dir1 = os.path.join(data_dir,'data/yawn_data')\n","print(data_dir1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DrowsinessDetection\n","/content/drive/MyDrive/DrowsinessDetection/data/yawn_data\n"]}]},{"cell_type":"markdown","metadata":{"id":"ebPdW6d9r6oW"},"source":["## Yawn Dataset\n","\n","Classes ''yawn' and ''no_yawn'\n","\n","no_yawn = 726 images\n","\n","yawn = 734 images"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDUj-9hC1d3r","executionInfo":{"status":"ok","timestamp":1635670821843,"user_tz":-60,"elapsed":4493,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"a398f01a-9fd6-426c-bafd-5a754f5e3449"},"source":["data_transform = transforms.Compose([\n","        transforms.Resize((28,28)),     #Questionable?\n","        transforms.Grayscale(),               \n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n","    ])\n","\n","#turn into greyscale???\n","yawn_dataset = datasets.ImageFolder(data_dir1, transform=data_transform)\n","\n","print(len(yawn_dataset))\n","trainset, testset = torch.utils.data.random_split(yawn_dataset, [len(yawn_dataset)-150, 150])\n","\n","classes = ['yawn', 'no_yawn']\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)\n","\n","print(len(trainset))\n","print(len(testset))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1450\n","1300\n","150\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bcXw1UncXli","executionInfo":{"status":"ok","timestamp":1635670830028,"user_tz":-60,"elapsed":8202,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"6a9ffd30-6501-422f-927d-aa6eb5ede760"},"source":["#Plot a few images in greyscale\n","images, labels = iter(trainloader).next()\n","#tests.plot_images(images[:8], n_rows=2)\n","print(images[0].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 28, 28])\n"]}]},{"cell_type":"markdown","metadata":{"id":"OCAy8Zr4u80j"},"source":["## ResNet\n","\n","We create a network with an architecure inspired by [ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n","\n","### ResNet block\n","Our ResNet consists of blocks with two convolutional layers and a skip connection.\n","\n","In the most general case, our implementation should have:\n","\n","<img src=\"https://drive.google.com/uc?id=1yHFVSWDnE_4N8zjLZtNIFCZ374L887rh\" width=220 style=\"float: right;\">\n","\n","* Two convolutional layers with:\n","    * 3x3 kernel\n","    * no bias terms\n","    * padding with one pixel on both sides\n","    * 2d batch normalization after each convolutional layer.\n","\n","* **The first convolutional layer also (optionally) has:**\n","    * different number of input channels and output channels\n","    * change of the resolution with stride.\n","\n","* The skip connection:\n","    * simply copies the input if the resolution and the number of channels do not change.\n","    * if either the resolution or the number of channels change, the skip connection should have one convolutional layer with:\n","        * 1x1 convolution **without bias**\n","        * change of the resolution with stride (optional)\n","        * different number of input channels and output channels (optional)\n","    * if either the resolution or the number of channels change, the 1x1 convolutional layer is followed by 2d batch normalization.\n","\n","* The ReLU nonlinearity is applied after the first convolutional layer and at the end of the block.\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>Note:</b> Batch normalization is expected to be right after a convolutional layer.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"2GZcivLZu80o"},"source":["<img src=\"https://drive.google.com/uc?id=1M_PC7w7mRVrp8bbW4hIUpNH67iYJtTWQ\" width=650 style=\"float: top;\">\n","\n","The implementation should also handle specific cases such as:\n","\n","Left: The number of channels and the resolution do not change.\n","There are no computations in the skip connection.\n","\n","Middle: The number of channels changes, the resolution does not change.\n","\n","Right: The number of channels does not change, the resolution changes."]},{"cell_type":"markdown","metadata":{"id":"J4s-Y_4qu80p"},"source":["Your task is to implement this block. You should use the implementations of layers in `nn.Conv2d`, `nn.BatchNorm2d` as the tests rely on those implementations."]},{"cell_type":"code","metadata":{"id":"S2pa7h8ou80s"},"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        \"\"\"\n","        Args:\n","          in_channels (int):  Number of input channels.\n","          out_channels (int): Number of output channels.\n","          stride (int):       Controls the stride.\n","        \"\"\"\n","        super(Block, self).__init__()\n","        \n","        self.block_layers = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels , 3, stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","        \n","        # YOUR CODE HERE\n","        if in_channels == out_channels:\n","            if stride != 1:\n","                #print(\"Stride > 1, same channels  \", stride)\n","                self.block_skip = nn.Sequential(\n","                    nn.Conv2d(in_channels, out_channels , 1, stride, bias=False),\n","                    nn.BatchNorm2d(out_channels)\n","                )\n","            else:\n","                self.block_skip = nn.Sequential()\n","        else:\n","            #print(\"Unequal channels  \", stride)\n","            self.block_skip = nn.Sequential(    \n","                nn.Conv2d(in_channels, out_channels , 1, stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","            \n","        self.block_relu = nn.Sequential(\n","            nn.ReLU()\n","        )\n","        \n","    def forward(self, x):\n","        # YOUR CODE HERE\n","        #print(\"Input :\" , x.shape)\n","        y = self.block_layers(x)\n","        #print(\"Layers :\" , y.shape)\n","        a = self.block_skip(x)\n","        #print(\"Skip :\" , a.shape)\n","        y = y + a\n","        #print(\"Before relu :\" , y.shape)\n","        y = self.block_relu(y)\n","        #print(\"After relu :\" , y.shape)\n","        return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtSIOFETu80w","executionInfo":{"status":"ok","timestamp":1635670830455,"user_tz":-60,"elapsed":440,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"6bdf5f37-f97a-4701-98b2-e8709cf78655"},"source":["def test_Block_shapes():\n","\n","    # The number of channels and resolution do not change\n","    batch_size = 20\n","    x = torch.zeros(batch_size, 16, 28, 28)\n","    block = Block(in_channels=16, out_channels=16)\n","    y = block(x)\n","    assert y.shape == torch.Size([batch_size, 16, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n","\n","    # Increase the number of channels\n","    block = Block(in_channels=16, out_channels=32)\n","    y = block(x)\n","    assert y.shape == torch.Size([batch_size, 32, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n","\n","    # Decrease the resolution\n","    block = Block(in_channels=16, out_channels=16, stride=2)\n","    y = block(x)\n","    assert y.shape == torch.Size([batch_size, 16, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n","\n","    # Increase the number of channels and decrease the resolution\n","    block = Block(in_channels=16, out_channels=32, stride=2)\n","    y = block(x)\n","    assert y.shape == torch.Size([batch_size, 32, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n","\n","    print('Success')\n","\n","test_Block_shapes()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Success\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwOdbMYwu80z","executionInfo":{"status":"ok","timestamp":1635670830456,"user_tz":-60,"elapsed":32,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"4411cb59-8e8c-45d0-909e-250126dae752"},"source":["tests.test_Block(Block)\n","tests.test_Block_relu(Block)\n","tests.test_Block_batch_norm(Block)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Success\n","Success\n","Success\n"]}]},{"cell_type":"markdown","metadata":{"id":"_6VSah8ru802"},"source":["### Group of blocks\n","\n","ResNet consists of several groups of blocks. The first block in a group may change the number of channels (often multiples the number by 2) and subsample (using strides).\n","\n","<img src=\"https://drive.google.com/uc?id=1EhVWIAmPSgook2W_m1l_Ig1PmYRwmxmr\"  width=200 style=\"float: left;\">"]},{"cell_type":"code","metadata":{"id":"bnRp08wQu806"},"source":["# We implement a group of blocks in this cell\n","class GroupOfBlocks(nn.Module):\n","    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n","        super(GroupOfBlocks, self).__init__()\n","\n","        first_block = Block(in_channels, out_channels, stride)\n","        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n","        self.group = nn.Sequential(first_block, *other_blocks)\n","\n","    def forward(self, x):\n","        return self.group(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZR-fd5tru808","executionInfo":{"status":"ok","timestamp":1635670830459,"user_tz":-60,"elapsed":26,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"d51daf29-dab3-45b3-da2d-477dfcf7abd2"},"source":["# Let's print a block\n","group = GroupOfBlocks(in_channels=10, out_channels=20, n_blocks=3)\n","print(group)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GroupOfBlocks(\n","  (group): Sequential(\n","    (0): Block(\n","      (block_layers): Sequential(\n","        (0): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","        (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (block_skip): Sequential(\n","        (0): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (block_relu): Sequential(\n","        (0): ReLU()\n","      )\n","    )\n","    (1): Block(\n","      (block_layers): Sequential(\n","        (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","        (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (block_skip): Sequential()\n","      (block_relu): Sequential(\n","        (0): ReLU()\n","      )\n","    )\n","    (2): Block(\n","      (block_layers): Sequential(\n","        (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","        (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (block_skip): Sequential()\n","      (block_relu): Sequential(\n","        (0): ReLU()\n","      )\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"Anp0EtBZu80_"},"source":["### ResNet\n","\n","Next we implement a ResNet with the following architecture. It contains three groups of blocks, each group having two basic blocks.\n","\n","<img src=\"https://drive.google.com/uc?id=1th0iWvYPHjW9eh5O6-Hqu1LOpg4urwxZ\" width=200 style=\"float: left;\">"]},{"cell_type":"markdown","metadata":{"id":"BM2rSzG0u81B"},"source":["The cell below contains the implementation of our ResNet."]},{"cell_type":"code","metadata":{"id":"qHk-3UA1u81E"},"source":["class ResNet(nn.Module):\n","    def __init__(self, n_blocks, n_channels=64, num_classes=2):\n","        \"\"\"\n","        Args:\n","          n_blocks (list):   A list with three elements which contains the number of blocks in \n","                             each of the three groups of blocks in ResNet.\n","                             For instance, n_blocks = [2, 4, 6] means that the first group has two blocks,\n","                             the second group has four blocks and the third one has six blocks.\n","          n_channels (int):  Number of channels in the first group of blocks.\n","          num_classes (int): Number of classes.\n","        \"\"\"\n","        assert len(n_blocks) == 3, \"The number of groups should be three.\"\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n","        self.bn1 = nn.BatchNorm2d(n_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.group1 = GroupOfBlocks(n_channels, n_channels, n_blocks[0])\n","        self.group2 = GroupOfBlocks(n_channels, 2*n_channels, n_blocks[1], stride=2)\n","        self.group3 = GroupOfBlocks(2*n_channels, 4*n_channels, n_blocks[2], stride=2)\n","\n","        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n","        self.fc = nn.Linear(4*n_channels, num_classes)\n","\n","        # Initialize weights\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, np.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x, verbose=False):\n","        \"\"\"\n","        Args:\n","          x of shape (batch_size, 1, 28, 28): Input images.\n","          verbose: True if you want to print the shapes of the intermediate variables.\n","        \n","        Returns:\n","          y of shape (batch_size, 10): Outputs of the network.\n","        \"\"\"\n","        if verbose: print(x.shape)\n","        x = self.conv1(x)\n","        if verbose: print('conv1:  ', x.shape)\n","        x = self.bn1(x)\n","        if verbose: print('bn1:    ', x.shape)\n","        x = self.relu(x)\n","        if verbose: print('relu:   ', x.shape)\n","        x = self.maxpool(x)\n","        if verbose: print('maxpool:', x.shape)\n","\n","        x = self.group1(x)\n","        if verbose: print('group1: ', x.shape)\n","        x = self.group2(x)\n","        if verbose: print('group2: ', x.shape)\n","        x = self.group3(x)\n","        if verbose: print('group3: ', x.shape)\n","\n","        x = self.avgpool(x)\n","        if verbose: print('avgpool:', x.shape)\n","\n","        x = x.view(-1, self.fc.in_features)\n","        if verbose: print('x.view: ', x.shape)\n","        x = self.fc(x)\n","        if verbose: print('out:    ', x.shape)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yhulScSu81I","executionInfo":{"status":"ok","timestamp":1635670852316,"user_tz":-60,"elapsed":21874,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"a1ff8dc1-efa0-4de7-d0d5-9643865ddd43"},"source":["def test_ResNet_shapes():\n","    # Create a network with 2 block in each of the three groups\n","    n_blocks = [2, 2, 2]  # number of blocks in the three groups\n","    net = ResNet(n_blocks, n_channels=10)\n","    net.to(device)\n","\n","    # Feed a batch of images from the training data to test the network\n","    with torch.no_grad():\n","        images, labels = iter(trainloader).next()\n","        images = images.to(device)\n","        print('Shape of the input tensor:', images.shape)\n","\n","        y = net.forward(images, verbose=True)\n","        print(y.shape)\n","        assert y.shape == torch.Size([trainloader.batch_size, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)\n","\n","    print('Success')\n","\n","test_ResNet_shapes()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the input tensor: torch.Size([32, 1, 28, 28])\n","torch.Size([32, 1, 28, 28])\n","conv1:   torch.Size([32, 10, 28, 28])\n","bn1:     torch.Size([32, 10, 28, 28])\n","relu:    torch.Size([32, 10, 28, 28])\n","maxpool: torch.Size([32, 10, 14, 14])\n","group1:  torch.Size([32, 10, 14, 14])\n","group2:  torch.Size([32, 20, 7, 7])\n","group3:  torch.Size([32, 40, 4, 4])\n","avgpool: torch.Size([32, 40, 1, 1])\n","x.view:  torch.Size([32, 40])\n","out:     torch.Size([32, 2])\n","torch.Size([32, 2])\n","Success\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"markdown","metadata":{"id":"kCeyaCN4u81K"},"source":["# Train the network"]},{"cell_type":"code","metadata":{"id":"cMNT-8vhu81M"},"source":["# This function computes the accuracy on the test dataset\n","def compute_accuracy(net, testloader):\n","    net.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in testloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__ieRggAu81N"},"source":["### Training loop\n","\n","In the cell below, implement the training loop. The recommended hyperparameters:\n","* Adam optimizer with learning rate 0.01.\n","* Cross-entropy loss. Note that we did not use softmax nonlinearity in the final layer of our network. Therefore, we need to use a loss function with log_softmax implemented, such as [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss).\n","* Number of epochs: 10\n","\n","We recommend you to use function `compute_accuracy()` defined above to track the accaracy during training. The test accuracy should be above 0.9.\n","\n","**Note: function `compute_accuracy()` sets the network into the evaluation mode which changes the way the batch statistics are computed in batch normalization. You need to set the network into the training mode (by calling `net.train()`) when you want to perform training.**"]},{"cell_type":"code","metadata":{"id":"u830o1Aju81Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635670852321,"user_tz":-60,"elapsed":55,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"962e8fef-6d41-42c9-e31f-8fbaf071700c"},"source":["# Create the network\n","n_blocks = [2, 2, 2]  # number of blocks in the three groups\n","net = ResNet(n_blocks, n_channels=16)\n","net.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (group1): GroupOfBlocks(\n","    (group): Sequential(\n","      (0): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential()\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","      (1): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential()\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","    )\n","  )\n","  (group2): GroupOfBlocks(\n","    (group): Sequential(\n","      (0): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential(\n","          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","      (1): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential()\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","    )\n","  )\n","  (group3): GroupOfBlocks(\n","    (group): Sequential(\n","      (0): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential(\n","          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","      (1): Block(\n","        (block_layers): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (block_skip): Sequential()\n","        (block_relu): Sequential(\n","          (0): ReLU()\n","        )\n","      )\n","    )\n","  )\n","  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n","  (fc): Linear(in_features=64, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"6aBQCPdhu81c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635671168320,"user_tz":-60,"elapsed":316043,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"38013fb7-4d68-4896-e6d7-647277050d90"},"source":["if not skip_training:\n","    # YOUR CODE HERE\n","    optimizer = optim.Adam(net.parameters(), lr=0.01)\n","    criterion = nn.CrossEntropyLoss()\n","    epochs = 1 #13\n","    net.train()\n","    for epoch in range(epochs):\n","        print(\"Epoch number:  \", epoch)\n","        for i, data in enumerate(trainloader, 0):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            output = net(images)\n","            output.to(device)\n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","            if i % 32 == 31:\n","                acc = compute_accuracy(net, testloader)\n","                print(\"Accuracy:  \", acc)\n","                net.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch number:   0\n","Accuracy:   0.5\n"]}]},{"cell_type":"code","metadata":{"id":"3d-Cxg_cu81l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635672222100,"user_tz":-60,"elapsed":2169,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"370305cb-b4df-4a2b-a411-3f6efb7c0918"},"source":["# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n","# Set confirm=False if you do not want to be asked for confirmation before saving.\n","if not skip_training:\n","  path = os.path.join(source_dir, 'resnet_yawn.pth')\n","  tools.save_model(net, path, confirm=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Do you want to save the model (type yes to confirm)? yes\n","Model saved to /content/drive/MyDrive/DrowsinessDetection/source/resnet_yawn.pth.\n"]}]},{"cell_type":"code","metadata":{"id":"G1H4aaQTu81t"},"source":["if skip_training:\n","    net = ResNet(n_blocks, n_channels=16)\n","    tools.load_model(net, 'resnet_yawn.pth', device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiBcXd7Tu81v","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1635672292312,"user_tz":-60,"elapsed":1620,"user":{"displayName":"Laker Kake","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14876978258477485141"}},"outputId":"0c24d88c-e9f6-4b4f-b55e-0aa1ed182785"},"source":["# Compute the accuracy on the test set\n","accuracy = compute_accuracy(net, testloader)\n","print('Accuracy of the network on the test images: %.3f' % accuracy)\n","n_blocks = sum(type(m) == Block for _, m in net.named_modules())\n","assert n_blocks == 6, f\"Wrong number ({n_blocks}) of blocks used in the network.\"\n","\n","assert accuracy > 0.9, \"Poor accuracy ({:.3f})\".format(accuracy)\n","print('Success')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the test images: 0.607\n"]},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-c943385fe3d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mn_blocks\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Wrong number ({n_blocks}) of blocks used in the network.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Poor accuracy ({:.3f})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Success'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Poor accuracy (0.607)"]}]}]}